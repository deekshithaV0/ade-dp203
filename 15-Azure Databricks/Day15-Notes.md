Day15-Azure Databricka

I learned that azure databricks is a collaborative analytics platform built on apace spark and it is designed for processing large datasets doing transformations,running notebooks and building complete data pipelines i got familiar with some key concepts like Workspace,Cluster,Notebooks and DBFS.setting up a databrick workspace and i connected with azure services and then i created a cluster with some basic compute options and made it clear with clusters that are essentially the runtime engines for spark.I also understood how to compute the autoscaling works and why should pick the the right cluster size that matters both in cost and performance wise.I loaded a sample file into databricka and saw how spark automatically figures out the schemma and loads data into dataframe then i connected databricks to azure data lake gen2 aand read data directly into spark and working with some dataframes by selecting columns,filtering rows,adding new columns and displaying results.I practiced grouping data by specific fields and calculating the metriccs like count,avg and sum.Spark handles the large datasets effieciently.Databricks has a built-in visulization tool so i tested out line charts,Bar charts and pie charts to see how it works and also understood some useful date functions like year(),month()and datediff() it would help me for tome series pipelines.Finally i worked with JSON files using from Json and practiced flattening nested structures which is something that deal with a lot in real world ETL.